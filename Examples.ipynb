{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in paper\n",
    "In the original paper, the authors used 16,000 documents from a subset of the TREC AP corpors(Harman, 1992). It is not easy to get the TREC datast since we need to sign an individual agreement and ask for approval from NIST. Instead, we download the sample data on [Blei's webpage](http://www.cs.columbia.edu/~blei/lda-c/). This sample is just a subset of the data that the authors used in the paper, so we cannot get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ldapkg.mymodel import LDA_OPT\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Functions used to preprocess the data\n",
    "def lemmatize_stemming(text):\n",
    "    '''\n",
    "    Lenmmatize and stem the text.\n",
    "    '''\n",
    "    return PorterStemmer().stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    '''\n",
    "    Preprocess the text.\n",
    "    '''\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions used to show the result\n",
    "import heapq\n",
    "def get_words(words_list, word_num):\n",
    "    '''\n",
    "    Get the words with largetest probilities in a specific topic.\n",
    "    words_list is a list of probability of words under a specific topic.\n",
    "    word_num is the number of words that we return.\n",
    "    Return the index of words in vocabulary.\n",
    "    '''\n",
    "    return list(map(words_list.index, heapq.nlargest(word_num, words_list)))\n",
    "\n",
    "def word_to_list(index, beta):\n",
    "    \"\"\"Transform the top_words into a list\"\"\"\n",
    "    topic = []\n",
    "    words_top = get_words(list(beta[:,index]), 10)\n",
    "    for i in words_top:\n",
    "        topic.append(vocabulary[i])\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ap = []\n",
    "\n",
    "with open(\"data/ap.txt\") as f:\n",
    "    for line in f:\n",
    "        if not (line.startswith(\"<\") or line.startswith(\" <\")):\n",
    "            ap.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_pd = pd.Series(ap)\n",
    "processed_ap = ap_pd.map(preprocess)  \n",
    "vocabulary = gensim.corpora.Dictionary(processed_ap)\n",
    "bow_corpus = [vocabulary.doc2bow(doc) for doc in processed_ap]\n",
    "doc = [dict(bow) for bow in bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda1 = LDA_OPT(30, 100, 100, 100)\n",
    "alpha1, beta1 = lda1.fit(doc, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Economy</th>\n",
       "      <th>Life</th>\n",
       "      <th>Politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>million</td>\n",
       "      <td>year</td>\n",
       "      <td>presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>work</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>market</td>\n",
       "      <td>peopl</td>\n",
       "      <td>forc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>billion</td>\n",
       "      <td>famili</td>\n",
       "      <td>reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stock</td>\n",
       "      <td>children</td>\n",
       "      <td>defens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month</td>\n",
       "      <td>live</td>\n",
       "      <td>talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>compani</td>\n",
       "      <td>health</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>busi</td>\n",
       "      <td>studi</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>point</td>\n",
       "      <td>life</td>\n",
       "      <td>sourc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>board</td>\n",
       "      <td>like</td>\n",
       "      <td>troop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Economy      Life   Politics\n",
       "0  million      year     presid\n",
       "1     year      work       unit\n",
       "2   market     peopl       forc\n",
       "3  billion    famili     reagan\n",
       "4    stock  children     defens\n",
       "5    month      live       talk\n",
       "6  compani    health    support\n",
       "7     busi     studi  statement\n",
       "8    point      life      sourc\n",
       "9    board      like      troop"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = word_to_list(18, beta1)\n",
    "list2 = word_to_list(0, beta1)\n",
    "list3 = word_to_list(8, beta1)\n",
    "dict1 = {'Life': list1, 'Economy': list2, 'Politics': list3}  \n",
    "result = pd.DataFrame(dict1) \n",
    "result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Dataset\n",
    "\n",
    "This dataset is named \"All the news\" and it is coming from [kaggle](https://www.kaggle.com/snapcrack/all-the-news). The dataset contains articles from New York Times, Breitbart, CNN, Business Insider, the Atlantic, Fox News and so on. The original dataset has three csv file, but we just use the first 1000 rows in the second file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = df[['content']].copy()\n",
    "document['index'] = document.index\n",
    "processed_docs = document['content'].map(preprocess)\n",
    "vocabulary = gensim.corpora.Dictionary(processed_docs)\n",
    "bow_corpus = [vocabulary.doc2bow(doc) for doc in processed_docs]\n",
    "doc = [dict(bow) for bow in bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda2 = LDA_OPT(10) \n",
    "alpha, beta = lda2.fit(doc, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Medical</th>\n",
       "      <th>President Election</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scientist</td>\n",
       "      <td>patient</td>\n",
       "      <td>presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>space</td>\n",
       "      <td>drug</td>\n",
       "      <td>busi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year</td>\n",
       "      <td>studi</td>\n",
       "      <td>organ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>medic</td>\n",
       "      <td>hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>planet</td>\n",
       "      <td>doctor</td>\n",
       "      <td>conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earth</td>\n",
       "      <td>health</td>\n",
       "      <td>properti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>climat</td>\n",
       "      <td>pain</td>\n",
       "      <td>elect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>univers</td>\n",
       "      <td>cancer</td>\n",
       "      <td>accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speci</td>\n",
       "      <td>vaccin</td>\n",
       "      <td>tabl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Astronomy  Medical President Election\n",
       "0        say      say              trump\n",
       "1  scientist  patient             presid\n",
       "2      space     drug               busi\n",
       "3       year    studi              organ\n",
       "4      human    medic              hotel\n",
       "5     planet   doctor           conflict\n",
       "6      earth   health           properti\n",
       "7     climat     pain              elect\n",
       "8    univers   cancer             accord\n",
       "9      speci   vaccin               tabl"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = word_to_list(4, beta)\n",
    "list2 = word_to_list(3, beta)\n",
    "list3 = word_to_list(2, beta)\n",
    "dict2 = {'President Election': list1, 'Medical': list2, 'Astronomy': list3}  \n",
    "result = pd.DataFrame(dict2) \n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
